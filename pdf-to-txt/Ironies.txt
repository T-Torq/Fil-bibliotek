Ironies of automation and their implications for public service automation
Ida Lindgren
Department of Management and Engineering, Link¨
oping University, Sweden
ARTICLE INFO
Keywords:
Automation
Public service
Robotic process automation
Ironies
Theory development
Local government
ABSTRACT
Automation of public service provision has gained renewed attention as emerging technologies are said to enable
automation of tasks that were previously seen as requiring human involvement. However, the merits of these
automation technologies are often exaggerated. More knowledge is needed on public service automation, and
much can be learned from adjacent research fields studying human-automation interaction. To lead by example,
this work applies Bainbridge’s (1983) concept of ironies of automation. The purpose is to (1) present ironies of
automation, (2) explicate how these ironies can come into play when implementing automated systems in the
public service context, and (3) outline implications that follow for public service automation. This is achieved by
relating ironies of automation to contemporary studies on Robotic Process Automation (RPA) developments in
Swedish local government. The analysis results in five ironies and a set of implications for public service
automation. The ironies and implications for public service automation direct attention to key challenges that
must be acknowledged in future automation implementations and show that further investigations and theoretical developments are needed on e.g., problems introduced by automation; tasks, roles, and responsibilities
that follow on automation; how to design the interface between humans and automated systems in a way that
facilitates monitoring, take-over, and maintenance; and, tools and methods for assessing the impact and quality
of automated systems. This paper thus provides a foundation for future empirical investigations and further
theoretical development on public service automation.
1. Introduction
Robotic Process Automation (RPA) has been highlighted as a new
and promising technology for achieving automation of work in government organizations. Automation is not a new phenomenon in government organizations but has gained renewed attention by both
practitioners and scholars as RPA, alongside various Artificial Intelligence (AI) applications, is said to enable automation of new types of
work, including tasks that were previously seen as requiring human
involvement (Penttinen et al., 2018; Wajcman, 2017). In this paper,
public service automation is in focus, referring to when government organizations implement digital automation technologies (and related
organizational changes) to execute parts of a public service process that
were previously carried out by human professionals.
The underlying aspiration of public service automation is to speed up
administrative work, improve decision quality, and reduce costs for
personnel in public service processes and provision. Many studies have
served to investigate potential uses, merits, and pitfalls of RPA in various
types of organizations and for different types of processes (e.g., Aguirre
& Rodriguez, 2017; Noppen et al., 2020; Willcocks & Lacity, 2016).
There is also a growing body of literature on RPA use and its impacts in
the public sector (e.g., Asatiani, 2022; Berg, 2022; Borry & GethaTaylor, 2019; Germundsson, 2022; Kaun, 2022; Veale & Brass, 2019).
Based on a comparison of RPA use in several types of organizations and
sectors, Eikebrokk and Olsen (2020) stated that RPA use in public sector
organizations have shown contradictory results and called for further
research on the nature and consequences of RPA use in the public sector
context.
As a research community, we are not lacking overly optimistic
statements of how new waves of automation will revolutionize and
transform public service provision to the better, nor dystopian descriptions of an AI-run future, with black-boxed decision-making as a
result (cf. Roehl, 2023). To avoid such extreme and unnuanced descriptions of public service automation, we need in-depth empirical
work that can capture different facets and nuances of automation. Digital government scholars can contribute with such empirical insights and
help guide RPA and AI developments and public service automation in
general. However, to truly advance on this topic, we do not only need
empirical studies on public service automation, but we must also find
better theoretical frameworks that can support a critical and nuanced
E-mail address: ida.lindgren@liu.se.
Contents lists available at ScienceDirect
Government Information Quarterly
journal homepage: www.elsevier.com/locate/govinf
https://doi.org/10.1016/j.giq.2024.101974
Received 21 January 2024; Received in revised form 13 September 2024; Accepted 19 September 2024
Government Information Quarterly 41 (2024) 101974
Available online 25 September 2024
0740-624X/© 2024 The Author. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
analysis of such studies and push the knowledge front forward. Theoretical frameworks for analyzing and understanding automation and its
consequences are already available in the literature, and we must do a
better job of applying these in our analyses.
In this paper, to lead by example, I use Lisanne Bainbridge’s (1983)
landmark paper Ironies of Automation to learn more about public service
automation. The purpose of this work is to (1) present ironies of automation, (2) explicate how these ironies can come into play when
implementing automated systems in the public service context, and (3)
outline implications that follow for public service automation. The
ironies refer to circumstances related to automation that, when combined, lead to the opposite of what is expected (Bainbridge, 1983). An
interesting aspect of these ironies is that they cannot be fully avoided;
organizations can, however, acknowledge these contradictory characteristics of automation and work to prevent their most negative effects
(Strauch, 2018). By addressing automation in this way, in which contradictory outcomes are allowed and acknowledged, we can form more
nuanced expectations of the outcomes of public service automation.
To achieve the purpose outline above, this work builds on a hermeneutic analysis of Bainbridge (1983), when set in relation to findings
from empirical studies on RPA developments in Swedish local government. This analysis is used to present five ironies associated with automation in general. With the help of these ironies, an account is given on
issues relating to RPA use in Swedish local government. Based on this
empirically based account, in combination with the general ironies, four
implications for public service automation are presented and discussed.
The implications illustrate that public service automation (1) introduces
new problems in the public service process, (2) creates new tasks, roles,
and responsibilities in the organization, (3) necessitates new types of
interfaces between humans and the automated system, and (4) necessitates new tools and methods for assessing process quality and return of
investments. The ironies and implications in combination thus direct
attention to key challenges that must be acknowledged in future public
service automation developments and implementations.
This work builds knowledge in a cumulative fashion by combining
Bainbridge’s work with current research findings from the public service
automation context. The ironies presented, and the implications outlined for public service automation, can be understood as theoretical
contributions that can be used to investigate, analyze, explain, and to
some extent even predict (cf. Gregor, 2006) consequences of automation
of public service processes. As such, this paper provides a foundation for
future empirical investigations and further theoretical development on
public service automation. This work is furthermore part of a special
issue on data-driven governance in the age of AI, contributing to the
issue with a deeper understanding of organizational aspects that must be
considered when public institutions and organizations use their data for
automation purposes.
The paper is organized in the following manner. In the next section, I
give a brief overview of the background of this paper. Thereafter, I
present and explain the hermeneutic analysis approach applied to
extract ironies from Bainbridge’s original text and relate these to public
service automation. I then proceed to present the main features of
Bainbridge’s (1983) argumentation and present five ironies of automation. Thereafter, an account is given on RPA developments and use in
Swedish local government, using the ironies as a theoretical lens. Last, I
outline implications for public service automation, followed by directions for future research.
2. Automation, RPA, and motivation for research
To address public service automation, we must first define the core
concept of automation. Automation can be defined in several ways but is
here understood as “the execution by a machine agent (usually a computer) of a function that was previously carried out by a human”
(Parasuraman & Riley, 1997, p. 231). Automation, as a term, thus both
refers to the digital technology used to exchange the human in the
process, and the change activities that make the exchange possible
(Lindgren & Scholta, 2023). For simplicity, I henceforth use the term
‘automated system’ to refer to the technology, and ‘automation’ to refer
to the change process. In this paper, focus furthermore lies on public
service automation, thus referring to when government organizations
implement automated systems (and related organizational changes) to
execute parts of a public service process that were previously carried out
by human professionals (Lindgren, 2023). Various digital technologies
can be used to achieve public service automation; here, Robotic Process
Automaton (RPA) is used as the empirical example of automation
technology.
2.1. Robotic process automation
RPA has been in use since about 2010 and is still considered a relatively new type of technology. As stated in the introduction to IEEEs
guide on intelligent process automation, RPA is “neither an operating
system nor an application, but a platform built to provide digital process
automation that mimics human operations in a digital environment”.
Furthermore, “it can use single or multiple applications or systems
through the standard human interface layer, in the same way a human
operator would” (IEEE Corporate Advisory Group, 2017, p.7). RPA thus
refers to a specific type of software that can be programmed to perform
structured work tasks (Penttinen et al., 2018) by imitating human users’
interactions in one or several systems (Lacity & Willcocks, 2021), e.g.,
mouse clicks, commands, and transferring data between different systems and platforms (Aguirre & Rodriguez, 2017).
Due to the characteristic of operating in and transferring data across
the user interfaces of other IT systems, RPA is often described as being a
‘lightweight’ form of IT (Bygstad, 2015) and non-invasive in relation to
the underlying systems (Osmundsen et al., 2019). These characteristics
are compared to those of traditional ‘heavyweight’ IT, i.e., systems
requiring integration through changes made in the underlying code
(Bygstad, 2017). The lightweight character of RPA is frequently used in
marketing, in which RPA is represented as an automation technology
that can be implemented and configured by personnel without specific
programming skills. Often, RPA is described as a technology that the
persons currently working in the process to be automated can configure
to support their own work, thus giving human workers the opportunity
to remove monotonous and repetitive tasks on their own initiative (see e.
g., Madakam et al., 2022). However, it is uncertain to what extent RPA is
used in this way in practice (Eikebrokk & Olsen, 2020).
In this paper, I refer to both RPA and AI. It is however important to
note that these terms are not used as synonyms. When RPA was first
introduced in the digital government context, it was often discussed as
being a form of AI, owing to its ability to ‘imitate’ the human user’s
clicks in the system and thus giving the software an impression of intelligence. However, specific RPA solutions vary in degree of sophistication and complexity. Most RPA solutions used today are simple and
rule-based scripts, without ‘intelligent’ features. There are however
more advanced RPA applications on the market that include AI components and decision-support, involving e.g., natural language processing tools, computer vision, and data analytics (Lacity & Willcocks,
2021; Madakam et al., 2022). RPA and AI are thus increasingly being
intertwined as technologies, but to avoid conceptual stretching it is
important to keep RPA and AI conceptually separate; considering that
RPA can be a ‘dumb’ technology, relying completely on rule-based and
pre-programmed scripts.
2.2. RPA in Swedish local government
One country in which RPA is increasingly being used by government
organizations is Sweden. Sweden has had a solid e-government development over time (United Nations, 2022) and a general drive for technological advancements on all levels of government. This means that the
public sector’s maturity is high concerning technologically driven
I. Lindgren Government Information Quarterly 41 (2024) 101974
2
developments in general, making it easier to isolate and understand
what is novel with RPA and how this technology fits into the already
established IT-landscape. As if in response to the call by Eikebrokk and
Olsen (2020) to investigate RPA use in the public sector, several scholars
have conducted empirical studies of RPA development, implementation,
and use in Swedish municipalities (e.g., Bernhard & Wihlborg, 2022;
Germundsson, 2022; Johansson et al., 2022; Lindgren, Johansson, et al.,
2022; Ranerup & Henriksen, 2022; Ranerup & Svensson, 2023). Opportunities to conduct empirical studies in this context are ample, as
many municipalities in Sweden have started using, or are considering
using, RPA as part of their administrative machinery (Juell-Skielse et al.,
2022).
The public service that has gained the most attention in the research
literature on automation and RPA use in Swedish local government is
that of social assistance (e.g., Germundsson, 2022; Germundsson &
Stranz, 2024; Ranerup & Svensson, 2023). One municipality has
attracted more attention than others: Trelleborg Municipality. Trelleborg municipality implemented an RPA solution in 2017 to reduce the
lead time in their handling of applications for social assistance. Their use
of RPA was allegedly the first of its kind in Swedish local government
and quickly gained media attention, in both positive and negative terms.
The municipality could showcase how RPA use had significantly shortened the time needed for handling applications forsocial assistance. This
caught the attention of policymakers such as the Swedish Association of
Local Authorities and Regions (SALAR), which subsequently published
several policy documents promoting RPA use in local government in
general (SALAR, 2018a; SALAR, 2018b). Critical voices claimed that
Trelleborg’s results were not only due to RPA, but because of reorganization, standardization of the process, and by reducing the social
workers’ power to practice discretion in the process. Other critics stated
that the RPA solution used did not adhere to public service regulations
and should be abandoned. Regardless of the criticism, other municipalities decided to procure RPA for their own purposes, based on the
promises of increased efficiency. Some municipalities have since tried to
automate the same process (social assistance), whereas others have
automated processes related to case handling of other public services (e.
g., applications for safety alarms to elderly and bus cards for school
children) or internal administration (e.g., forwarding invoices from one
department to another). Regardless of service process type, the main
motivation for using RPA in these processes has been to reduce costs for
human resources, as well as reduce lead time, unwanted variations, and
bias in case handling processes. In the Swedish local government
context, RPA has thus primarily been implemented to improve efficiency
(Germundsson, 2022), fueled by policymakers’ descriptions of RPA as a
means for speeding up work and increasing quality in administrative
processes (SALAR, 2018a; SALAR, 2018b). Amongst policymakers and
digital strategists working in Swedish municipalities, RPA has therefore
been associated with highly positive values and outcomes (Toll, 2022;
Toll et al., 2022), and has led to a vast array of RPA development projects across Swedish municipalities (Juell-Skielse et al., 2022).
Empirical studies of these RPA developments have touched on
several issues, e.g., employees’ interest for RPA adoption (Germundsson
& Stranz, 2024; Juell-Skielse et al., 2022), and effects of RPA on
decision-making and discretion (Ranerup & Henriksen, 2022), social
inclusion (Bernhard & Wihlborg, 2022), and public value creation
(Johansson et al., 2022; Ranerup & Svensson, 2023). Put together, these
studies provide rich descriptions of a phenomenon that has proven far
more challenging than envisioned by both policymakers and employees
in local government. With a few exceptions, the municipalities’ work to
implement RPA has been slow, difficult, and associated with many
problems (Johansson et al., 2022; Lindgren et al., 2024; Lindgren,
Johansson, et al., 2022; Ranerup & Svensson, 2023; Toll et al., 2023a,
2023b). Only a small set of municipalities have succeeded in making full
use of RPA thus far; whereas most municipalities covered in the
empirical studies have faced various challenges in their work to implement RPA and only implemented a handful RPA solutions in their
administrative processes. Furthermore, studies show how several municipalities have run RPA projects without a clear understanding of what
RPA can be used for (Soderstr ¨ om¨ et al., 2021), other than to keep up with
others and showcase a ‘modern’ organization (Toll et al., 2023a). Digital
government scholars can and should contribute with insights that can
help guide further RPA development and public service automation in
general. To advance our knowledge on this topic, we also need to learn
from adjacent research fields in which human-automation-interaction
has been studied for a longer period than in the digital government
field. In this paper, I claim that Lisanne Bainbridge’s classic work on
automation can support such knowledge development.
3. Research approach
To achieve a nuanced understanding of public service automation,
this paper presents insights from a hermeneutic analysis conducted in
two steps. First, I analyzed Bainbridge (1983) to determine a set of
ironies of automation. These ironies were briefly related to public service automation and RPA use in Swedish local government; the result of
which was published in a conference paper (Lindgren, 2023). Second, I
conducted a new round of analysis, further developing the analysis of
ironies of automation and expanding the literature on RPA to which the
ironies were related. Based on this second and more in-depth analysis, I
furthermore outlined a set of implications for public service automation.
In this section, these two steps of analysis are explained, starting with a
short introduction to Bainbridge (1983).
3.1. Brief introduction to Bainbridge’s original work
The work presented here builds on Lisanne Bainbridge’s short paper
published in Automatica in 1983. Bainbridge builds on socio-technical
systems theory (cf. Mumford, 2006) and cognitive science (cf. Gardner, 1987), and use empirical examples of automation in industrial
processes. She illustrates that automation can increase efficiency and
quality in industrial processes, but that it comes at a cost of losing insights into systems operations, as well as losing some control over said
operations. She points to contradictory issues caused by automation,
which she calls ironies, defined as “a combination of circumstances, the
result of which is the direct opposite of what might be expected”
(Bainbridge, 1983, p.775).
The title of Bainbridge (1983) – Ironies of Automation – implies that
she presents a set of clearly defined ‘ironies’ in her text; this is however
not the case. Rather, she presents a line of argument, in which contradictory aspects of automation are presented and discussed; some
explicitly, others implicitly. Still, many scholars have picked up on
Bainbridge’s idea of ironies of automation and continued to build on her
work. To date, researchers active in a multitude of different disciplines
and contexts have cited her paper approx. 3000 times (Google Scholar;
September 2024), and it is considered a landmark paper within the
research field of human factors engineering (Hancock, 2014; Strauch,
2018).
3.2. A hermeneutic analysis of ironies of public service automation
The analysis presented in this paper was triggered by an idea to
extract and clearly define a set of ironies of automation from Bainbridge’s original work and translate these to the public service automation context. To identify ironies relevant for public service
automation from the original text, a hermeneutic analysis of Bainbridge
(1983) was conducted. Hermeneutic analysis originates from literary
interpretation, e.g. Bible studies, and is a method for interpretating
meaning in textual data (Odman, ¨ 2017). With time, hermeneutic analysis has become a well-used analysis method in social sciences (Myers,
2009) and the information systems field (Boell & Cecez-Kecmanovic,
2014; Klein & Myers, 1999).
Hermeneutic analysis builds on the underlying assumption that (a)
I. Lindgren Government Information Quarterly 41 (2024) 101974
3
the text has an autonomous existence, independent of the author or the
world it describes, and (b) the interpretation is inherently guided and
shaped by the interpreter’s pre-understanding (Myers, 2009). Objectivity and replicability, in the positivistic sense, is not seen as possible
(nor desirable) in this type of analysis. Furthermore, hermeneutic
analysis builds on the underlying idea that we come to understand a
complex whole by forming notions about the meaning of its parts and
their interrelationships (Klein & Myers, 1999). The iterative movement
between the whole and its parts is represented by the hermeneutic circle,
through which the researcher moves back and forth, through multiple
iterations, between the general and the specific. This iterative analysis
approach builds on principles of e.g., contextualization; abstraction;
dialogical reasoning; allowing for multiple interpretations; and suspicion (Klein & Myers, 1999). An important aspect of understanding the
whole is furthermore to acknowledge the phenomenon’s particular social and historical context. The goal of the analysis is to form an internally coherent interpretation that is supported by the ‘facts’ of the
interpreted material, and in which gaps and contradictions are satisfactorily explained (Alvesson & Skoldberg, ¨ 2000). Klein and Myers
(1999, p.79) describes this process as “not unlike putting the pieces of a
puzzle together, except that the pieces are not all given but have to be
partially fashioned and adjusted to each other”.
3.2.1. First step of analysis
Building on the puzzle metaphor by Klein and Myers (1999), I
illustrate my research approach in Fig. 1. First, I conducted a careful
analysis of Bainbridge (1983) and extracted four ironies of automation
relevant for public service automation. By relating these ironies to
publications presenting results from empirical studies on RPA use in
Swedish local government, I re-contextualized the ironies and fashioned
these according to features of the public service automation context. The
first step of the analysis resulted in a list of ironies and a discussion on
how these can be manifested in the Swedish local government context.
These findings were published in a conference paper (Lindgren, 2023)
and presented at the conference in question. Based on reviewer comments, and comments received during the conference, I then proceeded
to conduct a second round of analysis.
3.2.2. Second step of analysis
For the second step of the analysis, the results of which are presented
in this paper, I included a larger set of empirical studies than the one
used in the first round of analysis. The text by Bainbridge was also
carefully re-read. The purpose of this second round of analysis was to
gain a better understanding of organizational consequences associated
with automation in the public service context. These insights are presented as implications for public service automation at the end of this
paper. During the analysis, a fifth irony was also deduced by relating
Fig. 1. Research approach – a two-step hermeneutic analysis of Bainbridge (1983) in relation to literature on RPA use in Swedish local government.
I. Lindgren Government Information Quarterly 41 (2024) 101974
4
Bainbridge (1983) to the larger set of studies on RPA use in Swedish
local government.
The empirical examples used to discuss the ironies are predominantly taken from an extensive qualitative case study on RPA use in
Swedish local government (municipalities), conducted during
2020–2023 (see Lindgren, 2020), and funded by AFA Fors ¨ ¨
akring (eng.
AFA Insurance). The study built on interpretive data generated through
in-depth semi-structured interviews with (a) local government employees from several municipalities working in various roles affected by
public service automation, (b) consultants from private firms selling
RPA solutions, and (c) representatives of the Swedish Association of
Local Government and Regions (SALAR). As part of the project, various
analyses were made to better understand RPA development and implementation in terms of e.g., stakeholders involved, values guiding the
development, values realized through RPA use, and organizational
challenges encountered in various phases of RPA development and use.
Results from these analyses were published by researchers active in the
project, in both conference and journal articles (Lindgren, Åkesson,
et al., 2022; Lindgren et al., 2021; Lindgren et al., 2024; Lindgren,
Johansson, et al., 2022; Soderstr ¨ om¨ et al., 2021; Toll et al., 2020; Toll
et al., 2022; Toll et al., 2023a; Toll et al., 2023b; Toll & Soderstr ¨ om, ¨
2020) and a licentiate thesis (Toll, 2022). The analysis presented in this
paper can thus be understood as a kind of meta-analysis of the findings
presented in these publications. In addition, the analysis was strengthened by including an additional set of articles, written by other scholars,
all of which cover RPA use in Swedish local government, (e.g., Andersson et al., 2022; Bernhard & Wihlborg, 2022; Germundsson & Stranz,
2024; Gustafsson & Wihlborg, 2019; Johansson et al., 2022; JuellSkielse et al., 2022; Ranerup & Henriksen, 2022; Ranerup & Svensson,
2023; Wihlborg et al., 2016).
The findings reported on RPA use in Swedish local government have
been used to fashion the puzzle pieces to fit the public service automation context. The choice of using examples from only one country and
level of government is partly based on convenience, as I have extensive
experience of studying RPA development and use in this setting. However, and more importantly, using experiences from one country and
level of government helps to keep certain contextual circumstances
stable in the analysis, such as the underlying political, institutional, and
legal context. Although there are 290 municipalities in Sweden, and
they differ in size and circumstances, their operations rests on the same
legal structure and overall assignment.
4. Ironies of automation
In her work, Bainbridge (1983) discusses the use of automated systems in industrial work processes, including both physical robots and
computerized systems. There are four actors in her narrative: (1) the
operator; (2) the automated system; (3) the designer of the automated
system; and (4) the person with the ultimate responsibility of the process
output (the operator, or a manager). According to Bainbridge, the classic
aim of automation is “to replace human manual control, planning and
problem solving by automatic devices and computers” (1983, p. 775). In
comparison to automated systems, humans are seen as slow, unreliable,
inefficient, and as sources of error in the process. While the automated
system is working as intended, the process is effectively and efficiently
performed. Sooner or later, however, the automated system is bound to
malfunction, and problems will arise. The ironies of automation
addressed by Bainbridge (1983) mainly concern circumstances related
to continuous monitoring and maintenance of the automated system,
and how to resolve issues that emerge when the automated system
malfunctions.
The main argument for introducing automation is that the automated
system will improve the quality of the process by simplifying or taking
over tasks and decision-making from the human operator (Bainbridge,
1983). Automation is expected to reduce workload in the organization
and eliminate human error in the work process (e.g., tasks and decisionmaking). However, Bainbridge claims, there are inherent circumstances
associated with automation that, when combined, can result in the
direct opposite of what is expected from automation (i.e., ironies). The
ironies that follow on my analysis of Bainbridge’s argumentation are
summarized in Table 1, but further description of the main arguments in
Bainbridge’s text is needed to contextualize these ironies.
First, Bainbridge problematizes the underlying view on human
abilities and performance expressed in the discourse on automation. In
particular, the human operator is seen as unreliable and a source of error
in the process and must therefore be replaced by an automated system.
However, the designer of the automated system, who is most probably
also a human, is not seen in the same light. According to Bainbridge,
human weaknesses are highlighted in relation to the operator, and at the
same time downplayed in relation to those actors designing the automated system. This tendency is dangerous, as it prepares ground for
automation surprises. Furthermore, Bainbridge (1983) illustrates how
designers seldom can automate complete processes, leaving the operator
with a fragmented set of tasks. This can, in turn, lead to new operator
problems that falsely accentuate the view of human operators being
unreliable. Building on socio-technical systems theory (cf. Mumford,
2006), Bainbridge highlights that exchanging human operators with
automated systems in a particular process does not remove the risk of
human error affecting the output of that process. The automated system
is still placed within a larger socio-technical system in which (other)
humans are involved. Thus, automation does not per se eliminate human
error from the process and system operations; implementing an automated system can furthermore infer new types of error and problems in
that process and its output (Bainbridge, 1983).
Second, Bainbridge (1983) outlines what is left for the humans in the
process after an automated system has been implemented. In addition to
stating that some tasks in the process may be left to the human operator
also after automation, she sketches two new tasks that emerge: (1)
monitoring and (2) take-over. To ensure that the automated system
operates successfully, it must be monitored. When the system malfunctions, which it will atsome point or another, its operations must be taken
over by the human operator. Building on research on human cognition
(cf. Gardner, 1987), Bainbridge illustrates severe issues related to both
tasks. Monitoring computerized automated systems in real-time is not
possible due to the speed and black-boxed nature of the system’s operations. Monitoring is thus described as “one of the worst types [of tasks];
it is very boring but very responsible, yet there is no opportunity to
acquire or maintain the qualities required to handle the responsibility.”
(Bainbridge, 1983, p.776). She further illustrates that take-over is an
equally impossible task for the human operator, as “… when manual
take-over is needed there is likely to be something wrong in the process,
so that unusual actions will be needed to control it, and one can argue
that the operator needs to be more rather than less skilled” than before
(Bainbridge, 1983, p.775). This last aspect furthermore highlights that,
even though an automated system is implemented to reduce the influence of humans and their ‘weaknesses’ on the output of the process,
automation creates a situation where the ‘inferior’ human still must
superintend the automated system and compensate when it fails to
perform according to expectation. This, in turn, places higher demands
on the human operator (Bainbridge, 1983), and thus necessitates upskilling of the human operator after automation.
Based on the argumentation thus far, four ironies (#1–4 in Table 1)
can be deduced from Bainbridge’s work. Last, however, it is also possible
to deduce a fifth irony from her line of reasoning (#5 in Table 1), when
combined with experiences made of RPA use in Swedish local government. As expressed by Bainbridge (1983), automation is expected to
reduce workload in the organization and eliminate human error in the
work process. Consequently, automation is also expected to reduce costs
for human work in the process. At the same time, automation generates
increased work and costs in other parts of the organization, related to IT
and an increased need for highly skilled personnel (e.g., IT specialists,
consultants, legal experts). New tasks related to monitoring and takeI. Lindgren Government Information Quarterly 41 (2024) 101974
5
over can also drive new types of costs for the organization. Costs inferred
by automation are however likely to be distributed across several
functions in the organization, which can obscure the total cost of automation. These circumstances in combination means that automation can
come at a higher cost than that of manual work, without the organization fully realizing this.
5. Relating the ironies to RPA use in local government
In this section, I proceed to discuss and relate the ironies outlined
above to experiences made of RPA use in Swedish local government.
Through this account, I illustrate how the ironies can come into play
when implementing automated systems in the public service context. To
keep this account at a reasonable length, only irony #1 and #2 are
treated separately, and the remaining ironies are treated in
combinations.
5.1. Errare humanum est (to err is human) – irony #1
Bainbridge (1983) clearly criticized the techno-optimistic and
deterministic assumptions about the world that tend to guide automation and the design of automated systems. For example, the first irony
highlights the overly pessimistic view on the operators’ abilities to
perform their work, and the overly optimistic view on the designer’s
ability to amend for the operators’ flaws. It also highlights a general
fixation and exaggeration of human error, as if human operators’ individual mistakes can be meaningfully separated from the larger sociotechnical system. These aspects, criticized by Bainbridge, are clearly
visible in the discourse on automation in the Swedish context. A content
analysis of Swedish policy documents on automation in general shows
that the potential winnings of automation are often exaggerated, and
that potential risks associated with automation are downplayed in these
documents (Toll et al., 2020). Similarly, policy documents published by
SALAR, concerning public service automation in local government, are
skewed towards the overly positive view on automation (Toll, 2022).
The RPA development projects studied so far have thus been guided by
overly optimistic hopes (Lindgren et al., 2021; Soderstr ¨ om¨ et al., 2021),
fueled by exaggerated policy documents, and unnuanced yet successful
marketing (Toll & Soderstr ¨ om, ¨ 2020).
Similarly, the discussion on public service automation highlights the
need to reduce human error. This is clearly visible in the policy documents promoting RPA use in local government (e.g., SALAR, 2018a,
2018b), in which automation is presented as a way to reduce the risk of
error in human case workers’ information handling. Removing error
from the process is indeed central to RPA development, as well as hindering new errors from emerging because of automation; if not correctly
programmed, an RPA solution can make a large number of faulty actions
in a very short time. This is a well-known feature of RPA and the general
awareness of risking to introduce new errors is therefore high in RPA
development projects. The fear of making mistakes, and accommodating
for risks of future yet unknown errors, is also contributing to slow and
lengthy development projects.
Interestingly, the guiding policy documents also present automation
as a way of reducing bias in case workers’ decision-making. Bias is a
different kind of error than those addressed by Bainbridge (1983).
However, Bainbridge’s claim that new errors can be built into the
automated system applies also to bias. New forms of bias can be built
into the process, and into decisions made by the system, via the design of
the automated system or based on historical data used to train the system. This is addressed in the scholarly literature on RPA, in which there
are ongoing discussions on biases in algorithms and potential issues of
negative designer influences (Rizk & Lindgren, 2024), especially when
AI is involved in the RPA set-up. In relation to RPA use in Swedish local
government practice, the discussion on bias in underlying data or system
configurations has not been as prominent thus far. But this lack of
explicit attention to bias can probably be explained by the fact that most
RPA solutions in current use are rule-based, designed based on the underlying legal frameworks for the service in question, and do not yet
include machine learning algorithms or data analytics. If more generative technologies are used, bias embedded in the underlying data and
system design must be explicitly addressed.
The first irony thus highlights that no matter what actions are taken
to remove humans from the process by means of automated systems,
humans are still involved in the design, use, and monitoring of these
systems. The main lesson that can be drawn from Bainbridge (1983) on
this point is therefore to look for and prevent errors and problems in
more places than in the human operator’s actions, and to acknowledge
that new problems can be created because of the design and use of an
automated system. This also means that we must expand on our understanding of roles involved in the design of public service automation.
5.2. Roles involved in the design of automated systems – irony #1 and #2
Bainbridge (1983) addressed four different roles involved in automation. Of course, the roles used by Bainbridge must be understood as a
simplified proxy for a larger set of stakeholders. However, to better
understand public service automation and acknowledge the complexity
of stakeholders in the public sector setting (cf. Rowley, 2011), there is a
need to expand on one of the roles covered by Bainbridge: the designer
role.
Current studies on RPA use in Swedish local government clearly
illustrate a need to activate a large and varied set of stakeholders in the
design of the automated system (Lindgren, Johansson, et al., 2022;
Ranerup & Svensson, 2023; Toll et al., 2022). Said studies have illustrated that to design a functioning RPA solution for public service
automation, the designer must have in-depth knowledge about RPA
technology; the organization’s existing IT-infrastructure; the process to
be automated; and underlying legal frameworks that guide government
operations and the policy implementation in question (Lindgren et al.,
2024). These competences are not likely to be present in one individual
or profession; collaboration across a large set of stakeholders is therefore
needed to combine the right resources and competences (Lindgren,
Åkesson, et al., 2022; Lindgren, Johansson, et al., 2022). This, in turn,
puts pressure on the managers orchestrating RPA development, to
ensure buy-in on all levels, including the political level. Although the
need for involving many stakeholders is schoolbook material concerning
information systems and digital government developments in general,
many Swedish municipalities have learned this lesson the hard way by
failing to achieve this (Lindgren, Åkesson, et al., 2022). Involving
stakeholders with legal expertise early in the development process
seems to be an especially important lesson learned.
A related circumstance identified in the studies of RPA use in
Swedish local government, is that local government organizations often
lack formalized processes and methods for conducting and orchestrating
RPA projects. This involves both development and design of automated
systems, as well as processes for funding and implementation (Lindgren,
Åkesson, et al., 2022). Instead, the studied organizations have tended to
make up their own ad hoc methods for mapping processes and
designing, orchestrating, and implementing automated systems; pilotstudies with trial-and-error approaches have been frequently applied
(Lindgren, Johansson, et al., 2022). It seems as if the managers involved
have not been prepared for how RPA development will affect their work
content and responsibilities. Moreover, those with the most knowledge
of the process to be automated, the human operators, have often not
been sufficiently involved in these ad hoc RPA projects. As illustrated by
Andersson et al. (2022), the experience of female case workers involved
in social welfare is typically not given enough attention and acknowledgment in the design of automated systems in local government.
Managers and designers take lead of the development, without enough
understanding of the process they are about to automate (Andersson
et al., 2022; Johansson et al., 2022). Furthermore, funding beyond the
pilot-project is often missing. This combination of circumstances causes
I. Lindgren Government Information Quarterly 41 (2024) 101974
6
problems already in the development process and has led to several
failed RPA initiatives not proceeding beyond the pilot phase (Lindgren,
Åkesson, et al., 2022; Lindgren, Johansson, et al., 2022).
5.3. Tasks after automation – irony #2
The second irony directs our attention to what is left after an automated system has been designed and implemented, and how the human
operator still involved in the process is supported (or not) in handling
tasks that could not be automated. When automation works at its best,
the automated system does what it is programmed to do, and the human
operator has new work content that is supported by the automated
system. The ‘perfect’ use of RPA, as expressed by practitioners and
policymakers in the studies on RPA use in Swedish local government, is
that the RPA performs monotonous routine tasks and thus free up time
that case workers can spend on more valuable and meaningful tasks.
However, it remains an empirical question if local governments will
succeed to fully realize this vision. Also, removing all routine tasks does
not necessarily result in a good work environment, and calls for studies
on who gets to decide whether a task is routine or valuable (Berg, 2022).
The studies on RPA in Swedish local government referred to here
have not fully covered the aspect of fragmentation, but it must be noted
that in the Swedish local government context, most RPA systems
currently in use are not fully autonomous. Rather, the automated system
only performs parts of the process, and a human operator completes the
process by e.g., taking the formal decision. This is a form of fragmentation, even though the division of labor between system and human has
not been addressed in terms of fragmentation in the literature included
in this analysis. However, the extent to which this division of labor affects the human operator’s ability to successfully perform their work has
been extensively discussed, especially in terms of effects on street-level
bureaucrats’ ability to use discretion in decision-making after automation (e.g., Bernhard & Wihlborg, 2022; Ranerup & Henriksen, 2022;
Ranerup & Svensson, 2023; Wihlborg et al., 2016). When implementing
automated systems in public service processes, an important lesson to be
drawn from Bainbridge (1983) is thus to consider what tasks are left to
the human operator and how these tasks fit together to form a
comprehensive work situation for the humans interacting with the
automated system. If not properly contextualized, tasks left after automation can become meaningless and boring, or overly complicated and
stressful.
5.4. Monitoring and take-over – irony #3 and #4
Turning to the third and fourth ironies, relating to monitoring and
take-over, there is a generally expressed concern that automated systems
in public service provision will eventually black-box decision grounds
and the decision-making process. This concern is expressed both in the
literature and in public service automation practice. The black box could
potentially be opened for inspection using monitoring systems, with
interfaces towards the human operator in charge of monitoring.
Regarding RPA use in Swedish local government, RPA solutions in use
typically send notifications to the human operator through email when
something is wrong in the process. But, as highlighted by Bainbridge
(1983), even if the system operations and decision grounds are made
visible initially, it is likely to be difficult to maintain visibility and understanding over time (See Table 1).
Bainbridge (1983) illustrated that the use of automated systems
initially tends to rely on the experiences of the humans who used to work
in the process, and their ability to compensate for issues that arise after
automation. This tendency is clearly visible in the studies on RPA use in
Swedish local government, showing that issues and tasks related to
monitoring have typically been observed and addressed too late in the
implementation process (Lindgren, Johansson, et al., 2022). This, in
turn, has created problems related to monitoring and take-over after the
automated system has been implemented, and for some organizations,
these tasks have come as a surprise (Toll et al., 2023b). In some municipalities, these tasks have evolved as case workers involved in the
design of the RPA solution have developed new skills related to both
process and technology (Lindgren, Johansson, et al., 2022). These skills
Table 1
Ironies of automation relevant for public service automation. Based on Bainbridge (1983) and Lindgren (2023, p.400-401).
IRONY DESCRIPTION
Irony #1
Related to the underlying view on human abilities.
All humans involved can be potential sources of error and it is impossible to eliminate the risk for error
altogether. Eliminating the human operator from the process does not necessarily eliminate the risk of error in
the process. For example, designer errors can be a major source of operating problems. Automation is not per
se a way of eliminating error from the process and system operations; rather, automation can be a new source
of error and problems.
Irony #2
Related to consequences of automation, in particular fragmentation of
work.
Automation requires that all actions of the system can be defined and programmed into the automated system.
With complex work tasks and processes, not all aspects are likely to be of this programmable character.
Therefore, the designer who tries to eliminate the operator through automation still leaves the operator with
the tasks the designer cannot think how to automate. Due to automation, the operator can be left with an
arbitrary collection of fragmented tasks. This fragmentation, in turn, can be a source of new types of error and
problems in the process, as well as increased stress and decreased job satisfaction for the operator.
Irony #3
Related to tasks left to the human after automation – monitoring the
automated system.
Automated systems require monitoring to ensure that they are performing successfully. Monitoring
automated systems in real-time is not possible for the human operator due to cognitive constraints. For this
reason, automated alarm systems are often put in place to monitor the automated system. Yet, the
responsibility of monitoring is put on the human operator or manager. Monitoring automated systems and
their alarm systems is very boring, but at the same time an important and highly responsible task. Due to the
speed and black-boxed nature of automated systems, there is no real opportunity to acquire or maintain the
qualities and knowledge required to handle the responsibility of monitoring. Monitoring thus risk being an
impossible task that can lead to new errors and problems in the process, as well as stress and decreased job
satisfaction for the person with the ultimate responsibility of the process output.
Irony #4
Related to tasks left to the human after automation – manual take-over
when the automated system malfunctions.
When the automated system fails and manual take-over is needed, the operator must be highly skilled and
knowledgeable not only in the operations of the automated system, but also in how the automated system
itself is functioning. This is an impossibility for highly advanced and sophisticated systems, especially if the
operator seldom gets to use these skills. Also, when a take-over is required, there is likely to be something
wrong in the process, so that unusual actions will be needed to solve the task. After automation, the operator
therefore needs to be more, rather than less, skilled than before.
Irony #5
Related to distribution of costs inferred by automation.
Automation is implemented to reduce costs associated with human work in the process. At the same time,
automation generates increased costs in other parts of the organization by increasing IT-related costs and
increasing the need for highly skilled personnel. Costs inferred by automation are likely to be distributed
across several functions in the organization, obscuring the total cost of automation. As a result, in total,
automation can come at higher cost than that of manual work, without the organization fully realizing this.
I. Lindgren Government Information Quarterly 41 (2024) 101974
7
set them apart from other case workers in the organization and, after the
automated system was implemented, made them suitable monitors of
the system. These individuals thus became responsible for supervising
the automated system, sometimes against their own will and interest,
since they were the only ones who truly understood the automated
system (Lindgren, Johansson, et al., 2022). In turn, this created a
dependence on a few individuals in the organization and thus an undesired vulnerability for the organization. Learning from Bainbridge
(1983), it is difficult, and potentially more difficult for each new generation of human operators interacting with the system, to ensure that
the human operator has the right skills to monitor the automated system
and compensate when it fails. Interestingly, however, there are also
examples of municipalities that have understood the challenge of
monitoring and retained human operators in the process, handling a
smaller subset of cases manually, to ensure that there are still people in
the organization that can monitor the automated system and do a takeover when necessary.
In the Swedish local government context, despite a vast array of RPA
development projects, fully automated systems are still novel and not
widely used. The general interest for utilizing this technology is however
high (Juell-Skielse et al., 2022). It is therefore important to take the
monitoring- and take-over issues seriously as this development progresses. Tasks related to monitoring and take-over are likely to significantly change the work content for many people working in close
proximity to automated systems. Already in 1983, Bainbridge forecasted
that it would become increasingly difficult to recruit people who have
the right skills – and interest – to work as supervisors of automated
systems. Thirty-one years later, Hancock (2014, p. 453) built on Bainbridge’s arguments and asked if humans will only be kept in the loop “in
order that blame can be attached to some living entity?”. This is a
relevant question to ask also in relation to public service automation and
highlights the need for policymakers and digital strategists to carefully
consider what roles people can play in an automated future.
5.5. Reskilling and reconfigurations of roles, responsibilities, and costs –
irony #1–5
Combining all ironies help to highlight that competences needed to
develop and interact with automated systems are different from those
required before automation. Also, because of automation, completely
new tasks emerge. These tasks must be carefully considered and
designed from the very beginning of the development. Bainbridge
(1983) highlighted monitoring and take-over as new core tasks after
automation. The studies on RPA use in Swedish municipalities highlight
an additional task: maintenance of the automated system, also discussed
in the general RPA literature (e.g., Asatiani, 2022).
As the automated system is developed, it is connected to other systems in the organization’s existing digital infrastructure. Apart from
maintaining the automated system through regular system updates, the
connections with other systems must also be continuously maintained
for the automated system to work properly. This is particularly true for
lightweight automation like RPA (Bygstad, 2015, 2017). The connections made between the RPA and the standard human interface layer of
the connected systems, i.e., the lightweight quality of the system,
changes the ways in which the system can be maintained (in comparison
to traditional IT systems). This characteristic has, so far, provided a
challenge for the traditional IT-departments at Swedish municipalities
(Lindgren, Åkesson, et al., 2022). New roles must be created, with responsibility for monitoring the automated system’s connections to other
systems and updating the automated system when needed.
Furthermore, the legal and political context in which the public
service operates must also be actively monitored – as changes in policies
and underlying legal frameworks affect rules and decisions embedded in
the design of the automated system (e.g., eligibility and payment
criteria). These changes must be continuously monitored and reflected
in the configuration and design of the automated system. However, this
is a different type of monitoring and maintenance than that related to
the technology and requires a different skillset. Thus, new tasks and
roles must be created related to other, policy-oriented, changes that may
affect the operations of the automated system. For the municipalities
covered in the studies on RPA use, this was typically an unexpected new
role when first introducing RPA in the organization (Lindgren, Johansson, et al., 2022).
All these new tasks related to automation and automated systems, as
well as the reallocation of responsibilities from the human operator to
other actors in the organization, call for substantial reorganization of
existing work processes, roles, and responsibilities. Such changes, in
turn, require resources and drive additional costs, and stands in contrast
to the intention of reducing costs through automation. The empirical
studies on RPA in Swedish local government show that it is difficult for
these organizations to form a complete picture of expenses related to
automation, and thus also assess whether costs are reduced by automation. If we look at the case handling process in isolation, in which the
need for human resources is reduced after an automated system is
implemented, costs may indeed have been reduced after automation.
But if we widen our gaze and include the increased costs associated with
automation as organizational change (e.g., procurement of new technology, additional IT personnel, consultants hired to configure the RPA,
process analysis and modeling, project management during development and implementation, new roles concerned with monitoring and
maintaining the system, and more), then a different picture is likely to
emerge. As illustrated in the empirical studies of RPA use in Swedish
local government, local government organizations often lack methods
for monitoring expenses that are distributed over several functions and
departments within the municipality. This, in turn, risks obscuring the
total cost of automation (Lindgren, Åkesson, et al., 2022). As indicated
by the fifth irony, automation can come at a higher cost than that of
manual work, without the organization fully realizing this. It should be
noted, however, that this may only be an initial problem. With time, it is
possible that there will be a return on the investments needed to
implement automated systems. However, new automation technologies
are continuously introduced on the market and RPA soon risk being
considered an outdated technology in need of replacement, thus driving
further needs for investments in new technology and upskilling of
personnel.
6. Implications for public service automation
From Bainbridge (1983) we can learn that government organizations
considering implementing automated systems must be prepared that, in
their attempt to improve processes through automation, they are
simultaneously likely to introduce new types of problems in the process
and organization. If not carefully designed, automated systems may
result in the direct opposite of what is expected (Bainbridge, 1983), as
indicated by the five ironies. These ironies are inherent to automation
and cannot be fully avoided (Strauch, 2018). Government organizations
can, however, acknowledge these ironies and work to prevent their most
negative effects. The account on RPA use in Swedish local government
furthermore explicates different ways in which the five ironies can come
into play in practice. Relating the ironies to current RPA use in Swedish
local government serves to retrospectively describe and partly explain
how and why RPA developments have been slow and difficult in this
context. Furthermore, the five ironies can be used for prediction of implications for public service automation in general. Based on the analysis
put forth in this paper, combining the insights from all five ironies and
the experiences made from RPA use in local government, a set of implications for public service automation can be outlined:
• Automation introduces new problems in the public service process. After automation, sooner or later, new errors and problems will
emerge in the process and affect its output. These are likely to be
unexpected and both qualitatively and quantitatively different than
I. Lindgren Government Information Quarterly 41 (2024) 101974
8
previously known problems. These can emerge based on e.g., the
operations and functionality of the automated system and its connections to other systems in the overall IT-infrastructure; the quality
of data used in the process; the automated system’s compliance with
underlying legal frameworks; human-automation interactions; and
reconfigurations of tasks and responsibilities in the organization.
Apart from monitoring the automated system, the organization must
thus design routines for how to handle automation surprises and
incidents that may occur.
• Public service automation necessitates new types of interfaces
between humans and the automated system. After automation,
even for fully autonomous systems, there will still be a need for
human interaction with the system. The design of the interfaces
through which humans interact with the automated system must not
be left to chance or ill-informed designers. Successful design of such
interfaces requires design processes that are mindful of human
cognition and how to present necessary information to the human
operator, in the right way and at the right time, as to not black-box
machine operations that the human is responsible for monitoring,
interacting with, and maintaining over time.
• Public service automation creates new tasks, roles, and responsibilities on multiple levels of the organization related to
development, implementation, monitoring, use, maintenance,
and management of the automated system. After automation,
new tasks and responsibilities emerge concerning monitoring of the
automated system and its operations and taking over operations
when needed. Also, new tasks and roles emerge in relation to e.g.,
developing the system, training the algorithm(s), maintaining the
system and related routines, and incident management. New tasks,
roles, and responsibilities require clear job descriptions and routines
for how to handle various issues in relation to the automated system.
These changes, in turn, creates a need for re- and up-skilling of
existing personnel, and recruitment of new professional roles. New
roles are likely to require expert competencies in relation to e.g.,
advanced automation technologies, systems integration, ITgovernance, change management, policy implementation, and
legal requirements.
• Public service automation necessitates new tools and methods for
assessing quality and return of investment. After automation,
process operations, tasks, roles, and responsibilities have changed.
What was previously done in one part and function of the organization, may now be distributed over several systems, roles, and
functions in the organization. To assess if an automated system is
living up to expectations, as well as understand its effects on policy
implementation, new tools and methods are needed for capturing
and assessing impact, quality, and return of investments.
Whereas the five ironies are formulated in a general manner, the
implications above are more direct and action-oriented and can serve as
a foundation for creating mitigating measures. The first implication is
derived from the first irony; the second implication is derived from a
combination of the second and third irony; and the third and fourth
implications build on a combination of all five ironies. Compared to
Bainbridge (1983), the implications presented here are rather obvious
extensions of her argumentation. However, in the empirical studies on
RPA use in local government addressed above, several of these aspects of
automation were reported as automation surprises. The ironies and
implications can thus be used in combination to guide organizations in
avoiding foreseeable problems, and to design tasks and routines for how
to deal with unforeseeable issues that arise when the automated system
is in use.
Please note that this paper is not meant as an argument against the
use of automated systems in public organizations and public service
provision. On the contrary, automated systems can be highly valuable in
this setting and be used for improving operations in public service
provision in many ways. Automated systems can also be used to perform
completely novel tasks that can add value to government organizations.
That being clearly stated, automated systems must not be introduced on
false grounds or overly optimistic expectations of the merits of these
systems (Eikebrokk & Olsen, 2020). The likelihood of succeeding with
public service automation will increase if automation is introduced
based on realistic expectations, rooted in an in-depth understanding of
its potential uses, requirements, and limitations. The ironies and implications for public service automation presented here can serve as a
useful reminder that even though automation can simplify specific
processes and tasks, automation can simultaneously add to the
complexity of public service provision.
7. Directions for future research
In this paper, new knowledge is presented by combining Bainbridge’s work with current research findings on RPA use in Swedish
local government. Based on the hermeneutic approach applied, this
work thus serves as a translation of ideas from one setting to another;
combining experiences made a long time ago, in a different automation
context, with experiences made in the current setting of public service
automation. Using the terminology of Shirley Gregor (2006), the
knowledge generated through this exercise can be understood as theoretical contributions that can be used to analyze, describe, explain, and
to some extent even predict public service automation. Consequently,
this paper provides a foundation for future empirical investigations and
further theoretical development on public service automation.
The ironies presented here build on extensive analysis of literature.
Irony #1–4, deduced directly from Bainbridge (1983), can be considered
as relatively robust and are likely to be transferable to many different
automation settings. However, irony #5 is a product of this paper, by
relating Bainbridge (1983) to the literature on RPA use in Swedish local
government. This irony must therefore be considered as a hypothesis
that is open for further investigation regarding its prevalence in public
service automation. The same goes for the implications presented. This
work furthermore used RPA as the empirical example of automation
technology. The lightweight character of RPA makes it different from
other automation technologies (Bygstad, 2015, 2017), and can affect the
transferability of the arguments made here. The ironies are likely to be
transferable to other automation technologies, but the implications
drawn for public service automation may differ slightly across different
types of automation technologies. Future work should investigate
whether this is the case.
Similarly, the work presented here is limited to one level of government (local level) and a specific geographical and cultural context
(Sweden). This is a clear limitation and calls for studies investigating the
ironies and their implications for public service automation on other
levels of government and in a wider geographical and cultural context.
The results presented here are likely to be transferable to many other
contexts than those addressed explicitly, but additional analysis can add
new facets and nuances to our understanding of public service automation on different levels of government and in different contexts. Also,
new facets and nuances can be added to our understanding of public
service automation by investigating the ironies and their implications in
relation to different theoretical perspectives, as well as different types of
public services. For example, differences in complexity of the underlying
legal frameworks and public policies are likely to influence to what
extent the ironies will come into play.
Last, to clearly connect this work to the wider theme of the special
issue, a final comment on AI is needed. New automation technologies
are currently being introduced on the market that include more
advanced AI applications, promising automation of an even wider set of
public services. Whether or not these promises will be fulfilled is an open
question. Still, the automation landscape will continue to evolve, calling
for continuous reinterpretations of what automation is, can, and should
be. This evolution also calls for continuous discussions on the potential
winnings and issues caused by automation in the public sector. The five
I. Lindgren Government Information Quarterly 41 (2024) 101974
9
ironies and their implications presented here can serve as a starting
point for such reinterpretations and discussions. They can also guide
analysis of how the use of AI applications triggers organizational
change, and the practical implications of such developments. For
example, the importance of having structured high-quality data is likely
to increase as generative AI applications are used and decision-making
becomes an autonomous task performed by an automated system.
How and by what (human) role in the organization should the quality of
these data be assured and monitored? What (human) role should be
responsible for the output generated by the system, what competence is
needed for taking on this responsibility, and what system interface is
needed for successfully communicating the grounds of the decision to
the person responsible? Based on the ironies and their implications, a
multitude of different questions can be asked that can guide a critical
and nuanced analysis of the use of AI and data-driven models for public
service automation purposes.
To conclude, a variety of research topics and questions for future
empirical investigation and theoretical development can be generated
based on this work, and the list of ironies and implications for public
service automation can be expanded. The ironies and implications presented here illustrate that further empirical investigations and theoretical developments are needed on e.g., (1) problems introduced by
automation; (2) tasks, roles, and responsibilities that follow on automation; (3) how to design the interface between humans and automated
systems in a way that facilitates monitoring, take-over, and maintenance; and, (4) tools and methods needed to assess the impact and
quality of automated systems in public service provision. Although
limited to a specific technology, context and organizational perspective,
the analysis presented here thus contributes with important insights on
automation in the public sector, helps unpack current developments,
builds knowledge in a cumulative fashion, and serves as a starting point
for further research and theorization.
CRediT authorship contribution statement
Ida Lindgren: Writing – review & editing, Writing – original draft,
Visualization, Resources, Project administration, Methodology, Investigation, Funding acquisition, Formal analysis, Conceptualization.
Declaration of competing interest
The authors declare that they have no known competing financial
interests or personal relationships that could have appeared to influence
the work reported in this paper.
The author is an Associate Editor for Government Information
Quarterly and was not involved in the editorial review or the decision to
publish this article.
Acknowledgements
This work was funded by AFA Fors ¨ akring ¨ (AFA Insurance), as part of
the research project “From Form to Robot?”, conducted 2020-2023
(project 190200). I wish to acknowledge my research colleagues at
Linkoping ¨ University for their active part in the research project and for
contributing to the publications referred to in this work: Daniel Toll,
Bjorn ¨ Johansson, Maria Booth, Aya Rizk, Ulf Melin, and Fredrik
Soderstr ¨ om. ¨ I especially wish to thank Ulf Melin for being an excellent
sounding board in the beginning of this writing process. I also extend my
gratitude to the participants in the Scandinavian Workshop on Electronic Government 2023, and the anonymous reviewers of the dg.o 2023
conference and Government Information Quarterly, for their constructive comments on earlier versions of this text. Last, I wish to thank
Mattias Lindgren for introducing me to Lisanne Bainbridge’s gem of a
paper and igniting the creative spark!
References
Aguirre, S., & Rodriguez, A. (2017). Automation of a business process using robotic process
automation (RPA): A case study (pp. 65–71). https://doi.org/10.1007/978-3-319-
66963-2_7
Alvesson, M., & Skoldberg, ¨ K. (2000). Reflexive methodology. New vistas for qualitative
research. Sage Publications.
Andersson, C., Hallin, A., & Ivory, C. (2022). Unpacking the digitalisation of public
services: Configuring work during automation in local government. Government
Information Quarterly, 39(1), Article 101662. https://doi.org/10.1016/j.
giq.2021.101662
Asatiani, A. (2022). What can public sector organizations learn from private sector
experience of robotic process automation?. In Service automation in the public sector.
Springer.
Bainbridge, L. (1983). Ironies of automation. Automatica, 19(6), 775–779. https://doi.
org/10.1016/0005-1098(83)90046-8
Berg, M. (2022). Hate it? Automate it!. In Everyday automation (pp. 157–170). Routledge.
Bernhard, I., & Wihlborg, E. (2022). Bringing all clients into the system – Professional
digital discretion to enhance inclusion when services are automated. Information
Polity, 27(3), 373–389. https://doi.org/10.3233/IP-200268
Boell, S. K., & Cecez-Kecmanovic, D. (2014). A hermeneutic approach for conducting
literature reviews and literature searches. Communications of the Association for
Information Systems, 34. https://doi.org/10.17705/1CAIS.03412
Borry, E. L., & Getha-Taylor, H. (2019). Automation in the public sector: Efficiency at the
expense of equity? Public Integrity, 21(1), 6–21. https://doi.org/10.1080/
10999922.2018.1455488
Bygstad, B. (2015). The coming of lightweight IT. In European conference on information
systems.
Bygstad, B. (2017). Generative innovation: A comparison of lightweight and
heavyweight IT. Journal of Information Technology, 32(2), 180–193. https://doi.org/
10.1057/jit.2016.15
Eikebrokk, T. R., & Olsen, D. H. (2020). Robotic process automation and consequences
for knowledge workers; a mixed-method study. Responsible Design, Implementation
and Use of Information and Communication Technology, 12066, 114–125. https://doi.
org/10.1007/978-3-030-44999-5_10
Gardner, H. (1987). The mind’s new science: A history of the cognitive revolution. Basic
books.
Germundsson, N. (2022). Promoting the digital future: The construction of digital
automation in Swedish policy discourse on social assistance. Critical Policy Studies, 16
(4), 478–496. https://doi.org/10.1080/19460171.2021.2022507
Germundsson, N., & Stranz, H. (2024). Automating social assistance: Exploring the use of
robotic process automation in the Swedish personal social services. International
Journal of Social Welfare, 33(3), 647–658. https://doi.org/10.1111/ijsw.12633
Gregor, S. (2006). The nature of theory in information systems. MIS Quarterly, 30(3),
611–642. https://doi.org/10.2307/25148742
Gustafsson, M. S., & Wihlborg, E. (2019). ‘It is always an individual assessment’: A case
study on challenges of automation of income support services. In I. Lindgren,
M. Janssen, H. Lee, A. Polini, M. P. Rodríguez Bolívar, H. J. Scholl, & E. Tambouris
(Eds.), Vol. 11685. Electronic government (pp. 45–56). Springer International
Publishing. https://doi.org/10.1007/978-3-030-27325-5_4.
Hancock, P. A. (2014). Automation: How much is too much? Ergonomics, 57(3), 449–454.
https://doi.org/10.1080/00140139.2013.816375
IEEE Corporate Advisory Group. (2017). IEEE guide for terms and concepts in intelligent
process automation (IEEE Std 2755-2017). IEEE. https://doi.org/10.1109/
IEEESTD.2017.8070671
Johansson, J., Thomsen, M., & Åkesson, M. (2022). Public value creation and robotic
process automation: Normative, descriptive and prescriptive issues in municipal
administration. Transforming Government: People, Process and Policy, 17(2), 177–191.
https://doi.org/10.1108/TG-11-2021-0193
Juell-Skielse, G., Güner, E., & Han, S. (2022). Adoption of robotic process automation in the
public sector: A survey study in Sweden. Linkoping, ¨ Sweden: Electronic Government.
EGOV 2022. Electronic Government. EGOV 2022. https://doi.org/10.1007/978-3-
031-15086-9_22
Kaun, A. (2022). Suing the algorithm: The mundanization of automated decision-making
in public services through litigation. Information, Communication & Society, 25(14),
2046–2062. https://doi.org/10.1080/1369118X.2021.1924827
Klein, H. K., & Myers, M. D. (1999). A set of principles for conducting and evaluating
interpretive field studies in information systems. MIS Quarterly, 23(1), 67–93.
https://doi.org/10.2307/249410
Lacity, M., & Willcocks, L. (2021). Becoming strategic with intelligent automation. MIS
Quarterly Executive, 169–182. https://doi.org/10.17705/2msqe.00047
Lindgren, I. (2020). Exploring the use of robotic process automation in local government.
In , 2797. Research-in-progress, available in CEUR proceedings EGOV-CeDEM-ePart (pp.
249–258). http://www.CEUR-WS.org/Vol-2797/paper24.pdf.
Lindgren, I. (2023). Ironies of public service automation – Bainbridge revisited. In
Proceedings of the 24th annual international conference on digital government research
(pp. 395–404). https://doi.org/10.1145/3598469.3598514
Lindgren, I., Åkesson, M., Thomsen, M., & Toll, D. (2022). Organizing for robotic process
automation in local government: Observations from two case studies of robotic
process automation implementation in Swedish municipalities. In G. Juell-Skielse,
I. Lindgren, & M. Åkesson (Eds.), Service automation in the public sector (pp. 189–203).
Springer International Publishing. https://doi.org/10.1007/978-3-030-92644-1_10.
Lindgren, I., Johansson, B., Soderstr ¨ om, ¨ F., & Toll, D. (2022). Why is it difficult to
implement robotic process automation?: Empirical cases from Swedish
municipalities. In M. Janssen, C. Csaki, ´ I. Lindgren, E. Loukis, U. Melin, G. Viale
I. Lindgren Government Information Quarterly 41 (2024) 101974
10
Pereira, … E. Tambouris (Eds.), Vol. 13391. Electronic government (pp. 353–368).
Springer International Publishing. https://doi.org/10.1007/978-3-031-15086-9_23.
Lindgren, I., & Scholta, H. (2023). Untangling the relationship between public service
automation and no-stop government. In I. Lindgren, C. Cs´
aki, E. Kalampokis,
M. Janssen, G. Viale Pereira, S. Virkar, … A. Zuiderwijk (Eds.), Vol. 14130. Electronic
government (pp. 83–94). Springer Nature Switzerland. https://doi.org/10.1007/978-
3-031-41138-0_6.
Lindgren, I., Toll, D., Johansson, B., Booth, M., Rizk, A., & Melin, U. (2024).
Organizational conditions required to implement RPA in local government: Insights
from a Swedish case study. In Proceedings of the 25th annual international conference
on digital government research (pp. 434–442). https://doi.org/10.1145/
3657054.3657257
Lindgren, I., Toll, D., & Melin, U. (2021). Automation as a driver of digital transformation
in local government: Exploring stakeholder views on an automation initiative in a
Swedish municipality. In DG.O2021: The 22nd annual international conference on
digital government research (pp. 463–472). https://doi.org/10.1145/
3463677.3463685
Madakam, S., Holmukhe, R. M., & Revulagadda, R. K. (2022). The next generation
intelligent automation: Hyperautomation. JISTEM - Journal of Information Systems
and Technology Management, 19, Article e202219009. https://doi.org/10.4301/
S1807-1775202219009
Mumford, E. (2006). The story of socio-technical design: Reflections on its successes,
failures and potential. Information Systems Journal, 16(4), 317–342. https://doi.org/
10.1111/j.1365-2575.2006.00221.x
Myers, M. (2009). Qualitative research in business and management. Sage.
Noppen, P., Beerepoot, I., Van De Weerd, I., Jonker, M., & Reijers, H. A. (2020). How to
keep RPA maintainable? In D. Fahland, C. Ghidini, J. Becker, & M. Dumas (Eds.), Vol.
12168. Business process management (pp. 453–470). Springer International
Publishing. https://doi.org/10.1007/978-3-030-58666-9_26.
Odman, ¨ P.-J. (2017). Tolkning, forståelse, ¨ vetande. Hermeneutik i teori och praktik (3rd ed.)
Studentlitteratur.
Osmundsen, K., Iden, J., & Bygstad, B. (2019). Organizing robotic process automation:
Balancing loose and tight coupling. Hawaii International Conference on System
Sciences. https://doi.org/10.24251/HICSS.2019.829
Parasuraman, R., & Riley, V. (1997). Humans and automation: Use, misuse, disuse,
abuse. Human Factors: The Journal of the Human Factors and Ergonomics Society, 39(2),
230–253. https://doi.org/10.1518/001872097778543886
Penttinen, E., Kasslin, H., & Asatiani, A. (2018). How to choose between robotic process
automation and back-end system automation?. In European conference on information
systems, Portsmouth, UK.
Ranerup, A., & Henriksen, H. Z. (2022). Digital discretion: Unpacking human and
technological Agency in Automated Decision Making in Sweden’s social services.
Social Science Computer Review, 40(2), 445–461. https://doi.org/10.1177/
0894439320980434
Ranerup, A., & Svensson, L. (2023). Automated decision-making, discretion and public
values: A case study of two municipalities and their case management of social
assistance. European Journal of Social Work, 26(5), 948–962. https://doi.org/
10.1080/13691457.2023.2185875
Rizk, A., & Lindgren, I. (2024). Automated decision-making in the public sector: A
multidisciplinary literature review. In M. Janssen, et al. (Eds.), Lecture notes in
computer science: Vol. 14841. Electronic government. EGOV 2024. Cham: Springer.
https://doi.org/10.1007/978-3-031-70274-7_15.
Roehl, U. B. U. (2023). Automated decision-making and good administration: Views from
inside the government machinery. Government Information Quarterly, 40(4), Article
101864. https://doi.org/10.1016/j.giq.2023.101864
Rowley, J. (2011). E-government stakeholders—Who are they and what do they want?
International Journal of Information Management, 31, 53–62.
SALAR. (2018a). Automatisering av arbete. In , 5408. M¨
ojligheter och utmaningar f¨
or
kommuner, landsting och regioner. https://skr.se/download/18.5627773817e39e979e
f38d99/1642168328686/5408.pdf.
SALAR. (2018b). Automatisering av arendehantering ¨ —Att frig¨
ora tid f¨
or vardeskapande ¨
arbete.
Soderstr ¨ om, ¨ F., Johansson, B., & Toll, D. (2021). Automation as migration?. In Identifying
factors influencing adoption of RPA in local government.
Strauch, B. (2018). Ironies of automation: Still unresolved after all these years. IEEE
Transactions on Human-Machine Systems, 48(5), 419–433. https://doi.org/10.1109/
THMS.2017.2732506
Toll, D. (2022). Sociotechnical imaginaries of the automated municipality. Licentiate Thesis
No 129. Linkoping ¨ University.
Toll, D., Booth, M., & Lindgren, I. (2023a). Digitalization and automation for the sake of
IT? Insight from automation initiatives in Swedish municipalities. In Proceedings of
the 16th international conference on theory and practice of electronic governance (pp.
86–93). https://doi.org/10.1145/3614321.3614333
Toll, D., Booth, M., & Lindgren, I. (2023b). Robot colleagues in Swedish municipalities: How
RPA affects the work situation of employees. Budapest: Electronic Government. EGOV
2023. https://doi.org/10.1007/978-3-031-41138-0_11
Toll, D., Lindgren, I., & Melin, U. (2022). Stakeholder views of process automation as an
enabler of prioritized value ideals in a Swedish municipality. JeDEM - EJournal of
EDemocracy and Open Government, 14(2), 32–56. https://doi.org/10.29379/jedem.
v14i2.726
Toll, D., Lindgren, I., Melin, U., & Madsen, C.Ø. (2020). Values, benefits, considerations
and risks of AI in government. A study of AI policies in Sweden. JeDEM - EJournal of
EDemocracy and Open Government, 12(1), 40–60. https://doi.org/10.29379/jedem.
v12i1.593
Toll, D., & Soderstr ¨ om, ¨ F. (2020). What is this RPA they are selling?. In Poster, available in
CEUR proceedings EGOV-CeDEM-ePart (pp. 365–370).
United Nations. (2022). E-government survey 2022. The future of digital government. United
Nations.
Veale, M., & Brass, I. (2019). Administration by algorithm? Public Management meets
Public Sector Machine Learning., 1–30.
Wajcman, J. (2017). Automation: Is it really different this time? The British Journal of
Sociology, 68(1), 119–127. https://doi.org/10.1111/1468-4446.12239
Wihlborg, E., Larsson, H., & Hedstrom, K. (2016). “The computer says no!” – A case study
on automated decision-making in public authorities. In 2016 49th Hawaii
international conference on system sciences (HICSS) (pp. 2903–2912). https://doi.org/
10.1109/HICSS.2016.364
Willcocks, L., & Lacity, M. (2016). Service automation robots and the future of work. SB
Publishing.
Ida Lindgren is Associate Professor in Information Systems, Linkoping ¨ University, Sweden. She conducts research on information systems development in the public sector
context, focusing particularly on the interplay between digital public services, the public
encounter, and automation of work. Her work is published in e.g. Government Information
Quarterly, Transforming Government – People, Process, Policy, and in proceedings from
several IS and digital government conferences (e.g., IFIP EGOV, Digital Government
Society’s annual conference, ECIS).
I. Lindgren Government Information Quarterly 41 (2024) 101974
11